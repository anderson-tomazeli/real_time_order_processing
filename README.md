The main idea is to generate orders data by manually executing the place_order.py script located in the root project.
After script is ran, the service order_processor, which has a rabbitmq listening process, will catch the order data and store in the mongodb, also sending a message to the orders queue
The other service called notification-service, which is listening to the rabbitmq too, will put the sent message in the confirmations queue, finishing all the process
Everything is loggged into the .logs/app.log file, clarifying each step of the solution
As improvement, I'm writing a script to generate .json files to be consumed as the initial flow in an ETL process, since currently, these data are generated by the place_order.py, with no files involved.
